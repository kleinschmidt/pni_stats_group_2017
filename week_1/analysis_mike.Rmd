---
title: "Markus Analysis"
output: html_notebook
---

First, we load the data! 

```{r}
library(data.table)
d <- fread('~/Box Sync/Research/analysis software/markus_dots_data/batch2_33final.csv')
colnames(d) <- c("RT","log_RT","ID", "trial", "featureCorrelation", "TaskTransition", "congruency", "correct", "task", "Miniblock_all", "Miniblock_n")
summary(d)
```
Convert things to factors that are factors: 

```{r}
d[,TaskTransition:=as.factor(TaskTransition)]
levels(d$TaskTransition) <- c("NoTaskTransition","TaskTransition")
contrasts(d$TaskTransition) <- c(-0.5, 0.5)
d[,featureCorrelation:=as.factor(featureCorrelation)]
levels(d$featureCorrelation) <- c("Uncorrelated","Correlated")
contrasts(d$featureCorrelation) <- c(-0.5, 0.5)
d[,congruency:=as.factor(congruency)]
levels(d$congruency) <- c("Incongruent","Congruent")
contrasts(d$congruency) <- c(-0.5, 0.5)
```

Some figures! Since there is between-subject variation of within-subject effects, we don't want to just plot means and SEs computed from treating the whole dataset is i.i.d. But if we wanted to, here is one way to do this: 

```{r}
library(ggplot2)

p <- ggplot(d, aes(x=TaskTransition, y=log_RT)) + stat_summary(fun.data="mean_cl_normal") # by default mean_cl_boot returns SD. we want CI, which would be 
p
```

We can do this for the inputs we care about. One way to do this with ggplot would be to reshape the data just right and use facet_wrap with scale=free. But reshape has never made sense to me, so here is an alternative: 

```{r}
library(gridExtra)
p_taskTransition_naive <- ggplot(d, aes(x=TaskTransition, y=log_RT)) + stat_summary(fun.data="mean_cl_normal")
p_congruency_naive <- ggplot(d, aes(x=congruency, y=log_RT)) + stat_summary(fun.data="mean_cl_normal")
p_featureCorrelation_naive <- ggplot(d, aes(x=featureCorrelation, y=log_RT)) + stat_summary(fun.data="mean_cl_normal")
grid.arrange(p_taskTransition_naive, p_congruency_naive, p_featureCorrelation_naive, nrow=1)
```

Now, a better way of making this figure would be to somehow take out between-subject variability. One way would be to use some ideas from ANOVA theory for this, using a method from Morey 2008: 

```{r}
library(Rmisc)
library(plyr)
d_summarized <- llply(c('TaskTransition','congruency','featureCorrelation'), function(x) summarySEwithin(data=as.data.frame(d), measurevar='log_RT', withinvars=x, idvar='ID', na.rm=TRUE))
names(d_summarized) <- c('TaskTransition','congruency','featureCorrelation')
figurelist <- llply(c('TaskTransition','congruency','featureCorrelation'), function(x) ggplot(d_summarized[[x]], aes_string(x=x, y="log_RT")) + geom_point() + geom_linerange(aes(ymin=log_RT-se, ymax=log_RT+se)))
grid.arrange(figurelist[[1]], figurelist[[2]], figurelist[[3]], nrow=1)
```

Another way we could do this instead is let a mixed effects model figure it out for us: 

```{r}
library(lme4)
m1 <- lmer(log_RT ~ 0 + TaskTransition + (1|ID), data=d)
```


```{r}
m_lmer <- lmer(log_RT ~ TaskTransition * congruency * featureCorrelation + (1 | ID), data=d)
m_rstanarm <- stan_glmer(log_RT ~ TaskTransition * congruency * featureCorrelation + (1 | ID), data=d, algorithm = 'fullrank')
```